{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07abdb2c-953c-4764-a918-bbdacb0e5333",
   "metadata": {},
   "source": [
    "# HBV calibration\n",
    "\n",
    "This notebook is used to calibrate the parameters for the HBV model for the Loire river analysis. The period for calibration and validation period is divided in 1990-2014 for calibration and 2015-2019 for calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33da3f-074c-4665-9060-68345564c7a0",
   "metadata": {},
   "source": [
    "### 1. Importing general python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5c046f-4599-46b1-b39c-7f5a071e2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "#niceties\n",
    "from rich import print\n",
    "\n",
    "# Needed\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from scipy.stats import qmc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fadba2a-feba-423a-8f17-8d2cf72cb122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general eWaterCycle\n",
    "import ewatercycle\n",
    "import ewatercycle.models\n",
    "import ewatercycle.forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8980a1eb-8fe7-44dc-9c93-5c648fd8c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import drought analyser function\n",
    "%run Drought_analyser.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a14210-c265-4c46-a77d-034cbe7896bd",
   "metadata": {},
   "source": [
    "### 2. Defining experiment data and paths \n",
    "In this chapter all the variables are defined for the chosen basin. Also the loading and generating path are defined for the forcings and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3ec199-406e-4cf1-a5e3-4681a61af98b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/zoe/forcing/loire_river/ERA5-90-19'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# defining destination path for ERA5 data\u001b[39;00m\n\u001b[1;32m     12\u001b[0m forcing_path_ERA5 \u001b[38;5;241m=\u001b[39m Path\u001b[38;5;241m.\u001b[39mhome() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforcing\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloire_river\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERA5-90-19\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mforcing_path_ERA5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# model HBV destination path\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model_path_HBV \u001b[38;5;241m=\u001b[39m Path\u001b[38;5;241m.\u001b[39mhome() \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmp\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHBV_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/ewatercycle2/lib/python3.12/pathlib.py:1311\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1311\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/zoe/forcing/loire_river/ERA5-90-19'"
     ]
    }
   ],
   "source": [
    "# name of the catchment\n",
    "basin_name = \"FR003882\"\n",
    "\n",
    "# defining dates for calibration\n",
    "experiment_start_date = \"1990-01-01\"\n",
    "experiment_end_date = \"2019-12-31\"\n",
    "\n",
    "# defining path for catchment shape file\n",
    "station_shp = Path.home() / \"BEP-Loire\" / \"book\" / \"model_loire\" / \"estreams_cb_FR003882.shp\"\n",
    "\n",
    "# defining destination path for ERA5 data\n",
    "forcing_path_ERA5 = Path.home() / \"forcing\" / \"loire_river\" / \"ERA5-90-19\"\n",
    "forcing_path_ERA5.mkdir(exist_ok=True)\n",
    "\n",
    "# model HBV destination path\n",
    "model_path_HBV = Path.home() / \"tmp\" / \"HBV_model\"\n",
    "\n",
    "gdf = gpd.read_file(\"estreams_cb_FR003882.shp\")\n",
    "gdf = gdf.to_crs(epsg=2154)\n",
    "gdf[\"area_km2\"] = gdf.geometry.area / 1e6  \n",
    "basin_area = gdf[\"area_km2\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38a4979-7be5-4c35-8f70-6ad7194b9a65",
   "metadata": {},
   "source": [
    "### 3. Generating ERA5 forcings\n",
    "\n",
    "The ERA5 forcings can be generated using the marked out code below. If ERA5 is already generated, it can be loaded using option 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573bd3dc-bab4-49c8-98c7-531ef1aab32a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Forcing file /home/zoe/forcing/loire_river/ERA5-90-19/ewatercycle_forcing.yaml not found. Perhaps you want to use LumpedMakkinkForcing(...)?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m      2\u001b[0m ERA5_end_date \u001b[38;5;241m=\u001b[39m experiment_end_date\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT00:00:00Z\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Option 1: Generate forcings\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#ERA5_forcing = ewatercycle.forcing.sources[\"LumpedMakkinkForcing\"].generate(\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#   dataset=\"ERA5\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Option 2: Load forcings\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# get data from stored location \u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m ERA5_forcing \u001b[38;5;241m=\u001b[39m \u001b[43mewatercycle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforcing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLumpedMakkinkForcing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforcing_path_ERA5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ewatercycle2/lib/python3.12/site-packages/ewatercycle/base/forcing.py:276\u001b[0m, in \u001b[0;36mDefaultForcing.load\u001b[0;34m(cls, directory)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    272\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForcing file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerhaps you want to use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(...)?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m     )\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg)\n\u001b[1;32m    277\u001b[0m metadata \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39mread_text()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# Workaround for legacy forcing files having !PythonClass tag.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Remove it so ewatercycle.forcing.source[<forcing name>].load(dir) works.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Forcing file /home/zoe/forcing/loire_river/ERA5-90-19/ewatercycle_forcing.yaml not found. Perhaps you want to use LumpedMakkinkForcing(...)?"
     ]
    }
   ],
   "source": [
    "ERA5_start_date = experiment_start_date+'T00:00:00Z'\n",
    "ERA5_end_date = experiment_end_date+'T00:00:00Z'\n",
    "\n",
    "# Option 1: Generate forcings\n",
    "#ERA5_forcing = ewatercycle.forcing.sources[\"LumpedMakkinkForcing\"].generate(\n",
    "#   dataset=\"ERA5\",\n",
    "#   directory= str(forcing_path_ERA5),\n",
    "#   start_time=ERA5_start_date,\n",
    "#   end_time=ERA5_end_date,\n",
    "#   shape=station_shp,\n",
    "#)\n",
    "\n",
    "# Option 2: Load forcings\n",
    "# get data from stored location \n",
    "ERA5_forcing = ewatercycle.forcing.sources[\"LumpedMakkinkForcing\"].load(directory=forcing_path_ERA5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7010d796-8014-4838-a416-e95dcac057d7",
   "metadata": {},
   "source": [
    "### 4. Defining historical data from eStreams\n",
    "\n",
    "The observerd discharges for the Blois station are loaded in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c0d812-b024-4535-9baf-84c95492fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_data = pd.read_csv(\"FR003882_streamflow_m3s.csv\", index_col='date', parse_dates=True)\n",
    "Q_obs = q_data[experiment_start_date:experiment_end_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ad971-e781-42c0-b8a1-8d1e63cb344c",
   "metadata": {},
   "source": [
    "### 5. Calibrate the parameters\n",
    "\n",
    "In this chapter multiple calibration methods are defined. The first method is RMSE. This method is used to check if the overall calibration method works accordingly. The second and third method are used to specifically calibrate on drought duration and deficit. Because the distribution method gave the best results, this is eventually used as final calibration method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4fd95-84de-4a94-b7de-b4fef1a82a1c",
   "metadata": {},
   "source": [
    "#### 5.1 Calibration method 1: RMSE\n",
    "For the first method 'Root Mean Squared Error' is used. This method is used first to check wether the rest of the calibration method works accordinglu, as this should give decent parameters for discharge. The first year of the modelled discharge is skipped for calibration, because the s_0 (initial storages) need time to fill. Also the code checks wether the mean_flow is lower than 100 m3/s, to speed up the process, as these values can never be a good Q_model and thus the parameters are not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e22c5ab-19d2-458b-8994-0723d010a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drought_calibration_objective1(modelOutput, observation, start_calibration, end_calibration):\n",
    "    # Combine modeled and observed data in one DataFrame\n",
    "    hydro_data = pd.concat([modelOutput.reindex(observation.index, method='ffill'), observation], axis=1)\n",
    "\n",
    "    # Select calibration period (skip first year)\n",
    "    start_calibration = str(int(start_calibration[:4]) + 1) + start_calibration[4:]\n",
    "    hydro_data = hydro_data[hydro_data.index > pd.to_datetime(pd.Timestamp(start_calibration).date())]\n",
    "    hydro_data = hydro_data[hydro_data.index < pd.to_datetime(pd.Timestamp(end_calibration).date())]\n",
    "    hydro_data = hydro_data.dropna(subset=[basin_name])\n",
    "\n",
    "    # Check if the discharge is not too low\n",
    "    mean_flow = hydro_data['model output'].mean()\n",
    "    if mean_flow < 100:\n",
    "        #print(f\"Skipping iteration: Mean flow {mean_flow:.2f} m³/s is too low.\")\n",
    "        return np.inf\n",
    "\n",
    "    # Use RMSE on filtered data\n",
    "    rms = mean_squared_error(hydro_data[0], hydro_data[1], squared=False)\n",
    "\n",
    "    return rms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7932e667-cb51-4740-a67c-d2326549611f",
   "metadata": {},
   "source": [
    "#### 5.2 Calibration method 2: Normal distribution\n",
    "\n",
    "This calibration method return the Earth Mover's Distance (EMD), which calculates the dissimilarity between two distributions (Modelled distribution and observed distribution). This is both done for duration and deficit. These two EMD's are added and returned in this function. The lower the EMD, the better the result.\n",
    "Also is check is done if the mean flow is not under 100 m3/s to speed up the process, as these discharges won't be a good fit for this model. And the amount of modelled droughts have to be equal to 0.5-1.5 times the observed droughts. This makes sure that parameter sets which cause too few/many droughts are left out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b532a8a-12cd-428c-8372-5754013207ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drought_calibration_objective2(modelOutput, observation, start_calibration, end_calibration):\n",
    "    # Combine modeled and observed data in one DataFrame\n",
    "    hydro_data = pd.concat([modelOutput.reindex(observation.index, method='ffill'), observation], axis=1)\n",
    "\n",
    "    # Select calibration period\n",
    "    start_calibration = str(int(start_calibration[:4]) + 1) + start_calibration[4:]\n",
    "    hydro_data = hydro_data[hydro_data.index > pd.to_datetime(pd.Timestamp(start_calibration).date())]\n",
    "    hydro_data = hydro_data[hydro_data.index < pd.to_datetime(pd.Timestamp(end_calibration).date())]\n",
    "    hydro_data = hydro_data.dropna(subset=[basin_name])\n",
    "    \n",
    "    mean_flow = hydro_data['model output'].mean()\n",
    "    if mean_flow < 100:  # Threshold check\n",
    "        return np.inf\n",
    "\n",
    "    # Run drought analyser on both modeled and observed data\n",
    "    drought_obs = drought_analyser(hydro_data[basin_name], basin_name, 66.5)\n",
    "    drought_model = drought_analyser(hydro_data['model output'], 'model output', 66.5)\n",
    "    \n",
    "    if not (\n",
    "        0.5 * drought_obs[\"Drought Number\"].iloc[-1] < drought_model[\"Drought Number\"].iloc[-1] < 1.5 * drought_obs[\"Drought Number\"].iloc[-1]\n",
    "    ):\n",
    "        return np.inf\n",
    "\n",
    "    # Extract drought duration and max deficit values\n",
    "    x_obs, y_obs = drought_obs[\"Duration (days)\"], drought_obs[\"Max Cumulative Deficit (m3/s)\"]\n",
    "    x_model, y_model = drought_model[\"Duration (days)\"], drought_model[\"Max Cumulative Deficit (m3/s)\"]\n",
    "\n",
    "    # Compute Earth Mover’s Distance\n",
    "    duration_emd = wasserstein_distance(x_obs, x_model)\n",
    "    deficit_emd = wasserstein_distance(y_obs, y_model)\n",
    "\n",
    "    total_distance = (duration_emd * 0.5) + (deficit_emd * 0.5)\n",
    "\n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da6337-31ea-400f-84c1-a603c979b1d8",
   "metadata": {},
   "source": [
    "#### 5.3 Calibration method 3: Fitted polynomial\n",
    "\n",
    "This calibration method calculates a 1st-degree polynomial fitted line for modelled and observed droughts based on duration and deficit. This method then return the difference in coefficients for these lines. The lower this difference, the better the parameters.\n",
    "Also a check is added that leaves out parameter sets that return a max. deficit which is too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "657170c8-8d50-431a-a610-91ef2a68455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drought_calibration_objective3(modelOutput, observation, start_calibration, end_calibration):\n",
    "    # Combine modeled and observed data in one DataFrame\n",
    "    hydro_data = pd.concat([modelOutput.reindex(observation.index, method='ffill'), observation], axis=1)\n",
    "    \n",
    "    # Select calibration period\n",
    "    start_calibration = str(int(start_calibration[:4]) + 1) + start_calibration[4:]\n",
    "    hydro_data = hydro_data[hydro_data.index > pd.to_datetime(pd.Timestamp(start_calibration).date())]\n",
    "    hydro_data = hydro_data[hydro_data.index < pd.to_datetime(pd.Timestamp(end_calibration).date())]\n",
    "    hydro_data = hydro_data.dropna(subset=[basin_name])\n",
    "    \n",
    "    mean_flow = hydro_data['model output'].mean()\n",
    "    if mean_flow < 100:  # Threshold check (adjust as needed)\n",
    "        #print(f\"Skipping iteration: Mean flow {mean_flow:.2f} m³/s is too low.\")\n",
    "        return np.inf\n",
    "\n",
    "    # Run drought analyser on both modeled and observed data\n",
    "    drought_obs = drought_analyser(hydro_data[basin_name], basin_name, 66.5)\n",
    "    drought_model = drought_analyser(hydro_data['model output'], 'model output', 66.5)\n",
    "    \n",
    "    if (\n",
    "        1.2 * drought_obs[\"Max Cumulative Deficit (m3/s)\"].min() < drought_model[\"Max Cumulative Deficit (m3/s)\"].min()\n",
    "    ):\n",
    "        #print(drought_obs[\"Max Cumulative Deficit (m3/s)\"].min(), drought_model[\"Max Cumulative Deficit (m3/s)\"].min())\n",
    "        return np.inf\n",
    "\n",
    "    # Fit linear lines to both datasets\n",
    "    x_obs, y_obs = drought_obs[\"Duration (days)\"], drought_obs[\"Max Cumulative Deficit (m3/s)\"]\n",
    "    x_model, y_model = drought_model[\"Duration (days)\"], drought_model[\"Max Cumulative Deficit (m3/s)\"]\n",
    "\n",
    "    if len(x_obs) > 1 and len(x_model) > 1:\n",
    "        coeffs_obs = np.polyfit(x_obs, y_obs, 1)\n",
    "        coeffs_model = np.polyfit(x_model, y_model, 1)\n",
    "    else:\n",
    "        #print(f\"Insufficient data points for polyfit ({len(x_obs)}, {len(x_model)}).\")\n",
    "        return np.inf\n",
    "\n",
    "    # Calculate sum of difference between polynomial coefficients and distribution\n",
    "    poly_diff = np.sum(np.abs(coeffs_obs - coeffs_model))\n",
    "\n",
    "    return poly_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f69a4-996d-4d55-96a7-2dc0db4802af",
   "metadata": {},
   "source": [
    "#### 5.4 Start calibrating\n",
    "\n",
    "For the calibration we need to define sets of parameters. These sets are defined using a range for each parameter and then the sets are semi-randomly generated using a Latin Hypercube sampler, which makes sure that the parameters sets are well distributed. For this research a sample size of 2000 sets is used. A greater size did not result in better parameters. Then, the discharges are generated for each set of parameters and assessed using drought_calibration_objective2. At the end unnecessary data is deleted, as we only need the objective (which is the return value of the objective function).\n",
    "\n",
    "At this moment N=20, as a sample size of 2000 can take up to 2 hours of calibraing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b2379e-f7c8-4113-8c75-f9d9227be320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial storage for the model\n",
    "#               Si,  Su, Sf, Ss, Sp\n",
    "s_0 = np.array([0,  100,  0,  15, 0])\n",
    "\n",
    "\n",
    "# Define parameter ranges for the model\n",
    "p_min = np.array([0,   0.2,  40,    .5,   .001,   1,     .01,  .0001,  .01])\n",
    "p_max = np.array([8,    1,  800,   4,    .3,     10,    .1,   .01,  0.5])\n",
    "\n",
    "# Sample random parameter combinations\n",
    "N = 20\n",
    "parameters = np.zeros([9, N])\n",
    "\n",
    "# Create a Latin Hypercube sampler\n",
    "sampler = qmc.LatinHypercube(d=9)\n",
    "sample = sampler.random(n=N)\n",
    "\n",
    "# Scale the sample to match the parameter ranges\n",
    "parameters = qmc.scale(sample, p_min, p_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94acd1a8-c3e7-4e25-a1c4-0266531e3a8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ERA5_forcing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m ensemble \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m counter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N): \n\u001b[0;32m----> 4\u001b[0m     ensemble\u001b[38;5;241m.\u001b[39mappend(ewatercycle\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mHBVLocal(forcing\u001b[38;5;241m=\u001b[39m\u001b[43mERA5_forcing\u001b[49m))\n\u001b[1;32m      5\u001b[0m     config_file, _ \u001b[38;5;241m=\u001b[39m ensemble[counter]\u001b[38;5;241m.\u001b[39msetup(\n\u001b[1;32m      6\u001b[0m                             parameters \u001b[38;5;241m=\u001b[39m parameters[counter],\n\u001b[1;32m      7\u001b[0m                             initial_storage\u001b[38;5;241m=\u001b[39ms_0,\n\u001b[1;32m      8\u001b[0m                             cfg_dir \u001b[38;5;241m=\u001b[39m model_path_HBV,\n\u001b[1;32m      9\u001b[0m                                )\n\u001b[1;32m     10\u001b[0m     ensemble[counter]\u001b[38;5;241m.\u001b[39minitialize(config_file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ERA5_forcing' is not defined"
     ]
    }
   ],
   "source": [
    "ensemble = []\n",
    "\n",
    "for counter in range(N): \n",
    "    ensemble.append(ewatercycle.models.HBVLocal(forcing=ERA5_forcing))\n",
    "    config_file, _ = ensemble[counter].setup(\n",
    "                            parameters = parameters[counter],\n",
    "                            initial_storage=s_0,\n",
    "                            cfg_dir = model_path_HBV,\n",
    "                               )\n",
    "    ensemble[counter].initialize(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61ea4f0c-0f0f-4e7f-be21-484c3322cc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02113884dd8042128d408abe3e816415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Progress bar for visualization\n",
    "f = IntProgress(min=0, max=N)\n",
    "display(f)\n",
    "\n",
    "# Array to store objective values\n",
    "objectives = []\n",
    "\n",
    "# Loop over ensemble members\n",
    "for ensembleMember in ensemble:\n",
    "    Q_m = []\n",
    "    time = []\n",
    "    while ensembleMember.time < ensembleMember.end_time:\n",
    "        ensembleMember.update()\n",
    "        discharge_this_timestep = ensembleMember.get_value(\"Q\")\n",
    "        Q_m.append(discharge_this_timestep[0])\n",
    "        time.append(pd.Timestamp(ensembleMember.time_as_datetime.date()))\n",
    "\n",
    "    # Create DataFrame for model results\n",
    "    Q_m = convert_Qsim_mmday_to_m3s(np.array(Q_m), basin_area)\n",
    "    discharge_dataframe = pd.DataFrame({'model output': Q_m}, index=pd.to_datetime(time))\n",
    "\n",
    "    # Calculate the custom drought-based objective function\n",
    "    objective_this_model = drought_calibration_objective2(\n",
    "        discharge_dataframe, \n",
    "        Q_obs, \n",
    "        experiment_start_date, \n",
    "        experiment_end_date\n",
    "    )\n",
    "    objectives.append(objective_this_model)\n",
    "\n",
    "    # Free up memory\n",
    "    del Q_m, time, discharge_dataframe, objective_this_model\n",
    "    f.value += 1\n",
    "\n",
    "# Clean up models to save memory\n",
    "for ensembleMember in ensemble:\n",
    "    ensembleMember.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5128ed-5f7f-4316-bc1d-baab4524a819",
   "metadata": {},
   "source": [
    "### 6. Results\n",
    "\n",
    "The best fitting parameters are chosen based on the lowest objective value. This is done in the cell below. If the minimum value in the objective list is equal to np.inf, no real parameter is chosen. This means that the parameter sets need to be adjusted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "386f8cc4-1045-4034-9b54-ad02edcc2b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.457875757565083</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4230702227959797</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">201.57602671208883</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.3649785293066605</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.26755301186057023</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.629648911384976</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.08356848543300459</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.003707325010773819</span>,\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.29644921009582514</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;36m4.457875757565083\u001b[0m,\n",
       "    \u001b[1;36m0.4230702227959797\u001b[0m,\n",
       "    \u001b[1;36m201.57602671208883\u001b[0m,\n",
       "    \u001b[1;36m2.3649785293066605\u001b[0m,\n",
       "    \u001b[1;36m0.26755301186057023\u001b[0m,\n",
       "    \u001b[1;36m8.629648911384976\u001b[0m,\n",
       "    \u001b[1;36m0.08356848543300459\u001b[0m,\n",
       "    \u001b[1;36m0.003707325010773819\u001b[0m,\n",
       "    \u001b[1;36m0.29644921009582514\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's also show the minimal values:\n",
    "parameters_minimum_index = np.argmin(np.array(objectives))\n",
    "if np.min(np.array(objectives)) == np.inf:\n",
    "    print(\"No real parameter is chosen\")\n",
    "\n",
    "parameters_minimum = parameters[parameters_minimum_index]\n",
    "\n",
    "print(list(parameters_minimum))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
