{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec436ed0-14fc-4985-bd19-5eb99fc2e04c",
   "metadata": {},
   "source": [
    "# HBV Calibration\n",
    "*RMSE & EMD*\n",
    "\n",
    "The Root Mean Square Error (RMSE) measures the average difference between a statistical model’s predicted values and the actual values, and it is mathematically the standard deviation of the residuals. Low RMSE values indicate that the model fits the data well and has more precise predictions, while higher values suggest more error and less precise predictions. It is a crucial metric used to assess the amount of error in a regression or other statistical model and indicates how well a model performs in predictive modeling (Frost, n.d.).\n",
    "\n",
    "The RSME formula for a sample is calculated as follows:\n",
    "\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{\\sum_{i=1}^{N}(y_i - \\hat{y}_i)^2}{N-P}} $$\n",
    "\n",
    "Where:\n",
    "\n",
    "•\n",
    "$\\mathbf{y_i}$ is the actual value for the $i^{th}$ observation.\n",
    "\n",
    "•\n",
    "$\\mathbf{\\hat{y}_i}$ is the predicted value for the $i^{th}$ observation.\n",
    "\n",
    "•\n",
    "$\\mathbf{N}$ is the number of observations.\n",
    "\n",
    "•\n",
    "$\\mathbf{P}$ is the number of parameter estimates, including the constant.\n",
    "\n",
    "\n",
    "This involves calculating the residual for each observation, squaring it, summing all squared residuals, dividing that sum by the error degrees of freedom (N - P), and finally taking the square root."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5c51d-893f-488f-889c-8c95e9dec5ee",
   "metadata": {},
   "source": [
    "## Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd089a07-e205-4df7-b638-3f03693fabd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some general python and eWaterCycle libraries need to be imported\n",
    "%matplotlib inline\n",
    "# General python\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import xarray as xr\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# Niceties\n",
    "from rich import print\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# General eWaterCycle\n",
    "import ewatercycle\n",
    "import ewatercycle.models\n",
    "import ewatercycle.forcing\n",
    "from ewatercycle.forcing import sources\n",
    "from ewatercycle.models import HBV\n",
    "\n",
    "# Optional: Data Assimilation\n",
    "# If not installed, uncomment below to install\n",
    "# !pip install ewatercycle-da\n",
    "from ewatercycle_DA import DA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d65bbc6-038e-482c-8ac9-c47187638374",
   "metadata": {},
   "source": [
    "## Choose region and time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf1a189d-d7e8-4902-a9b6-7591b80c4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the catchment\n",
    "basin_name = \"FR000119\"\n",
    "\n",
    "# defining dates for calibration\n",
    "experiment_start_date = \"2013-11-26T00:00:00Z\"\n",
    "experiment_end_date = \"2019-12-31T00:00:00Z\"\n",
    "\n",
    "#Define Catchment Area\n",
    "shapefile_path = Path.home() / \"BEP-Elke\" / \"book\" / \"thesis_projects\" / \"BSc\" / \"2025_Q4_ElkeSchokking_CEG\" / \"work in progress\" / \"ShapefilesFR000119\" / \"FR000119.shp\"\n",
    "\n",
    "#check\n",
    "catchment = gpd.read_file(shapefile_path)\n",
    "catchment = catchment.to_crs(epsg=3035)\n",
    "catchment[\"area_km2\"] = catchment.geometry.area / 1e6  \n",
    "basin_area = catchment[\"area_km2\"].sum()\n",
    "#catchment.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5485562-e12b-466f-b42c-69a56b96ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location forcing files in home directory\n",
    "forcing_path = Path.home() / \"forcing\" / \"FR000119\"/\"ERA5\"\n",
    "forcing_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2235d1a-3eb9-427d-b6e5-50848565fedd",
   "metadata": {},
   "source": [
    "## Generate ERA 5 Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8abd4fc5-f7ce-496b-af4f-fecdc30a4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option one: generate forcing:\n",
    "#ERA5_forcing = sources[\"LumpedMakkinkForcing\"].generate(\n",
    "    #dataset=\"ERA5\",\n",
    "    #start_time=experiment_start_date,\n",
    "    #end_time=experiment_end_date,\n",
    "    #shape=shapefile_path,\n",
    "#)\n",
    "\n",
    "# Option two: Load generated (merged) data\n",
    "forcing_dir = Path(\"/home/elke/BEP-Elke/book/thesis_projects/BSc/2025_Q4_ElkeSchokking_CEG/work in progress/esmvaltool_output/ewcrep5yvtlv4f_20250525_104347/work/diagnostic/script\")\n",
    "ERA5_forcing = sources[\"LumpedMakkinkForcing\"].load(directory=forcing_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92374f0a-73da-4f37-97dd-831cd33aed07",
   "metadata": {},
   "source": [
    "## Defining historical data from eStreams\n",
    "The original CSV file had some formatting and encoding issues—like strange quotation marks and all the data crammed into a single column—which made it impossible to load with the usual pandas.read_csv() method. To work around this, I used a custom parser to manually extract the dates and discharge values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "094c39b1-6e56-4394-9ecc-a23f3e48f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually parse the file\n",
    "dates = []\n",
    "discharges = []\n",
    "\n",
    "with open(\"A3550050.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        parts = line.replace('\"\"', '\"').strip().split(',\"')\n",
    "        if len(parts) >= 2:\n",
    "            date_str = parts[0].strip('\"')\n",
    "            discharge_str = parts[1].strip('\"')\n",
    "            try:\n",
    "                dates.append(pd.to_datetime(date_str))\n",
    "                discharges.append(float(discharge_str))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "discharge_series = pd.Series(discharges, index=dates, name=\"Discharge (m³/s)\")\n",
    "Q_obs = discharge_series[experiment_start_date:experiment_end_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b5b54-8161-4f90-846b-78d4365976dc",
   "metadata": {},
   "source": [
    "## Ensemble Initialization and Parameter Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30616e6f-be53-41da-9ade-6c2dda6cd5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HBV parameter bounds and names\n",
    "param_names = [\"Imax\", \"Ce\", \"Sumax\", \"Beta\", \"Pmax\", \"Tlag\", \"Kf\", \"Ks\", \"FM\"]\n",
    "p_min = np.array([0.0,  0.2,   40.0,  0.5,   0.001,   1.0,   0.01,  0.0001,  0.01])\n",
    "p_max = np.array([8.0,  1.0,  800.0,  4.0,   0.3,    10.0,   0.1,   0.01,   10.0])\n",
    "\n",
    "n_particles = 1000  # ensemble size\n",
    "\n",
    "# Sample random parameters for each particle within bounds\n",
    "parameters = np.zeros((len(param_names), n_particles))\n",
    "for j in range(len(param_names)):\n",
    "    parameters[j, :] = np.random.uniform(p_min[j], p_max[j], size=n_particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd97535d-53ea-4a54-aa37-56c8d3ddfaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble and initialize each member with HBV model and unique parameters\n",
    "ensemble = DA.Ensemble(N=n_particles)\n",
    "ensemble.setup()  # set up the ensemble environment\n",
    "\n",
    "# Prepare setup arguments for each particle (each gets its parameter set)\n",
    "setup_kwargs_list = [{'parameters': parameters[:, i]} for i in range(n_particles)]\n",
    "\n",
    "# Initialize all ensemble members with the HBVLocal model, forcing data, and parameters\n",
    "ensemble.initialize(model_name=[\"HBVLocal\"] * n_particles,\n",
    "                    forcing=[ERA5_forcing] * n_particles,\n",
    "                    setup_kwargs=setup_kwargs_list) \n",
    "\n",
    "# Choose a reference model for time tracking\n",
    "ref_model = ensemble.ensemble_list[0].model\n",
    "\n",
    "# Generate config file with first parameter set\n",
    "config_file, _ = ref_model.setup(parameters=parameters[:, 0])\n",
    "\n",
    "# Initialize model\n",
    "ref_model.initialize(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebd6bea-6539-4448-90d7-2b48b4d78a7c",
   "metadata": {},
   "source": [
    "## Running the Ensemble Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a3452e-3658-45a4-84c6-7f80f66de40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of time steps in the simulation period\n",
    "n_timesteps = int((ref_model.end_time - ref_model.start_time) / ref_model.time_step)\n",
    "\n",
    "time_index = []           # list to store timestamps for each time step\n",
    "ensemble_Q_outputs = []   # list to store discharge arrays for each time step\n",
    "\n",
    "for step in range(n_timesteps):\n",
    "    # Record current model time\n",
    "    current_time = pd.Timestamp(ref_model.time_as_datetime.date())\n",
    "    time_index.append(current_time)\n",
    "    \n",
    "    # Advance all models by one time step and collect their discharge values\n",
    "    ensemble.update()  # update all ensemble members by one step\n",
    "    Q_values = np.array(ensemble.get_value(\"Q\")).flatten()  # discharge of all particles\n",
    "    Q_values_m3s = Q_values * basin_area * 1000 / 86400 #convert to m3/s\n",
    "    ensemble_Q_outputs.append(Q_values_m3s)\n",
    "\n",
    "# Finalize the ensemble to release resources\n",
    "ensemble.finalize()\n",
    "\n",
    "# Convert collected outputs to a DataFrame for convenience\n",
    "Q_array = np.array(ensemble_Q_outputs)        # shape: (n_timesteps, n_particles)\n",
    "df_ensemble = pd.DataFrame(\n",
    "    data=Q_array, \n",
    "    index=pd.DatetimeIndex(time_index), \n",
    "    columns=[f\"particle_{i}\" for i in range(n_particles)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16ef914-7b58-46ce-9700-fc50c0e44170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_ensemble.shape)\n",
    "# print(df_ensemble.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ce629-d9c6-46b3-90c5-6a6ccbb808cc",
   "metadata": {},
   "source": [
    "## Defining the Calibration Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6309b70-d220-4485-944b-5d50f5ddce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_objective(simulated_series: pd.Series, observed_series: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Compute the calibration objective for a single model run by comparing \n",
    "    simulated and observed discharge series. The objective combines:\n",
    "      - RMSE on days with observed flow < 500 m³/s\n",
    "      - EMD between distributions of drought event durations\n",
    "    Lower values indicate a better fit to observations.\n",
    "    \"\"\"\n",
    "    # Align simulated series with observed series index\n",
    "    sim = simulated_series.loc[observed_series.index]\n",
    "    obs = observed_series\n",
    "\n",
    "    # 1. RMSE for days with observed discharge < 500 m³/s\n",
    "    low_flow_mask = obs < 500.0\n",
    "    if low_flow_mask.sum() == 0:\n",
    "        rmse_low_flow = 0.0  # no low-flow days, no penalty\n",
    "    else:\n",
    "        errors = sim[low_flow_mask] - obs[low_flow_mask]\n",
    "        rmse_low_flow = np.sqrt(np.mean(errors**2))\n",
    "\n",
    "    # 2. EMD between drought event durations\n",
    "    # Identify drought events in observed and simulated series\n",
    "    obs_droughts = droughts(obs, basin_name=\"obs\", q_crit=500)\n",
    "    sim_droughts = droughts(sim, basin_name=\"sim\", q_crit=500)\n",
    "    # Convert to DataFrame for\n",
    "    obs_droughts_df = pd.DataFrame(obs_droughts)\n",
    "    sim_droughts_df = pd.DataFrame(sim_droughts)\n",
    "    # Extract durations of each drought event\n",
    "    obs_durations = obs_droughts_df[\"Duration (days)\"].values\n",
    "    sim_durations = sim_droughts_df[\"Duration (days)\"].values\n",
    "    # Compute EMD (Wasserstein distance) between duration distributions\n",
    "    emd_duration = wasserstein_distance(obs_durations, sim_durations)\n",
    "\n",
    "\n",
    "    # Combine the three components into a single score\n",
    "    total_score = rmse_low_flow + emd_duration\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb057fe4-718d-4883-8e07-1317e6074517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Q_obs index sample: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DatetimeIndex</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008000; text-decoration-color: #008000\">'2013-11-26 00:00:00+00:00'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'2013-11-27 00:00:00+00:00'</span>,\n",
       "               <span style=\"color: #008000; text-decoration-color: #008000\">'2013-11-28 00:00:00+00:00'</span><span style=\"font-weight: bold\">]</span>,\n",
       "              <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'datetime64[ns, UTC]'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">freq</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Q_obs index sample: \u001b[1;35mDatetimeIndex\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'2013-11-26 00:00:00+00:00'\u001b[0m, \u001b[32m'2013-11-27 00:00:00+00:00'\u001b[0m,\n",
       "               \u001b[32m'2013-11-28 00:00:00+00:00'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "              \u001b[33mdtype\u001b[0m=\u001b[32m'datetime64\u001b[0m\u001b[32m[\u001b[0m\u001b[32mns, UTC\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m, \u001b[33mfreq\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">df_ensemble index sample: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DatetimeIndex</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008000; text-decoration-color: #008000\">'2013-01-01'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'2013-01-02'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'2013-01-03'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'datetime64[ns]'</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">freq</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "df_ensemble index sample: \u001b[1;35mDatetimeIndex\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'2013-01-01'\u001b[0m, \u001b[32m'2013-01-02'\u001b[0m, \u001b[32m'2013-01-03'\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[32m'datetime64\u001b[0m\u001b[32m[\u001b[0m\u001b[32mns\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m, \n",
       "\u001b[33mfreq\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Q_obs index sample:\", Q_obs.index[:3])\n",
    "print(\"df_ensemble index sample:\", df_ensemble.index[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f5d40-e059-477e-9acf-0b9c012f40b6",
   "metadata": {},
   "source": [
    "## Evaluating Performance and Selecting the Best Parameter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7caee127-3c0f-41cb-8c17-6535f8bc7d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported functions to: critical_days_module.py\n"
     ]
    }
   ],
   "source": [
    "from critical_days_module import droughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2e947a3-7167-42fe-8a7c-1513982d7bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Best score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.789</span> <span style=\"font-weight: bold\">(</span>part <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">767</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Best score: \u001b[1;36m52.789\u001b[0m \u001b[1m(\u001b[0mpart \u001b[1;36m767\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate objective for each ensemble member\n",
    "scores = []\n",
    "\n",
    "# Same datetime-index\n",
    "Q_obs.index = Q_obs.index.normalize()\n",
    "Q_obs.index = Q_obs.index.tz_localize(None)\n",
    "\n",
    "# Slice only the overlap \n",
    "Q_obs_aligned = Q_obs.loc[df_ensemble.index.min():df_ensemble.index.max()]\n",
    "\n",
    "for i in range(n_particles):\n",
    "    sim_series = df_ensemble[f\"particle_{i}\"]\n",
    "\n",
    "    if sim_series is None or sim_series.empty:\n",
    "        print(f\"Skipping particle_{i} (empty output)\")\n",
    "        scores.append(np.inf)  # Assign a bad score\n",
    "        continue\n",
    "\n",
    "    # Use the correct observation series (make sure Q_obs exists and matches in index)\n",
    "    score = calibration_objective(sim_series, Q_obs_aligned)\n",
    "    scores.append(score)\n",
    "\n",
    "scores = np.array(scores)\n",
    "best_index = np.argmin(scores)              # index of minimum objective value\n",
    "best_score = scores[best_index]             # lowest score\n",
    "best_params = parameters[:, best_index]     # parameter set corresponding to best score\n",
    "\n",
    "print(f\"Best score: {best_score:.3f} (part {best_index})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8eb397-b432-4555-a5c7-ad9b286ec5f2",
   "metadata": {},
   "source": [
    "## Outputting the Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9477af8-b5ef-4fbe-8ea3-a1c33a10aef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Best objective score: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52.7894</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Best objective score: \u001b[1;36m52.7894\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_53825 th {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_53825\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_53825_level0_col0\" class=\"col_heading level0 col0\" >Parameter</th>\n",
       "      <th id=\"T_53825_level0_col1\" class=\"col_heading level0 col1\" >Description</th>\n",
       "      <th id=\"T_53825_level0_col2\" class=\"col_heading level0 col2\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_53825_level0_row0\" class=\"row_heading level0 row0\" ></th>\n",
       "      <td id=\"T_53825_row0_col0\" class=\"data row0 col0\" >Imax</td>\n",
       "      <td id=\"T_53825_row0_col1\" class=\"data row0 col1\" >Maximum intensity</td>\n",
       "      <td id=\"T_53825_row0_col2\" class=\"data row0 col2\" >4.920400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53825_level0_row1\" class=\"row_heading level0 row1\" ></th>\n",
       "      <td id=\"T_53825_row1_col0\" class=\"data row1 col0\" >Ce</td>\n",
       "      <td id=\"T_53825_row1_col1\" class=\"data row1 col1\" >Coefficient of evaporation</td>\n",
       "      <td id=\"T_53825_row1_col2\" class=\"data row1 col2\" >0.719400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53825_level0_row2\" class=\"row_heading level0 row2\" ></th>\n",
       "      <td id=\"T_53825_row2_col0\" class=\"data row2 col0\" >Sumax</td>\n",
       "      <td id=\"T_53825_row2_col1\" class=\"data row2 col1\" >Field capacity</td>\n",
       "      <td id=\"T_53825_row2_col2\" class=\"data row2 col2\" >317.794800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53825_level0_row3\" class=\"row_heading level0 row3\" ></th>\n",
       "      <td id=\"T_53825_row3_col0\" class=\"data row3 col0\" >Beta</td>\n",
       "      <td id=\"T_53825_row3_col1\" class=\"data row3 col1\" >Shape coefficient</td>\n",
       "      <td id=\"T_53825_row3_col2\" class=\"data row3 col2\" >2.170800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53825_level0_row4\" class=\"row_heading level0 row4\" ></th>\n",
       "      <td id=\"T_53825_row4_col0\" class=\"data row4 col0\" >Pmax</td>\n",
       "      <td id=\"T_53825_row4_col1\" class=\"data row4 col1\" >Maximum percolation rate</td>\n",
       "      <td id=\"T_53825_row4_col2\" class=\"data row4 col2\" >0.066100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53825_level0_row5\" class=\"row_heading level0 row5\" ></th>\n",
       "      <td id=\"T_53825_row5_col0\" class=\"data row5 col0\" >Tlag</td>\n",
       "      <td id=\"T_53825_row5_col1\" class=\"data row5 col1\" >Time lag</td>\n",
       "      <td id=\"T_53825_row5_col2\" class=\"data row5 col2\" >5.206100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53825_level0_row6\" class=\"row_heading level0 row6\" ></th>\n",
       "      <td id=\"T_53825_row6_col0\" class=\"data row6 col0\" >Kf</td>\n",
       "      <td id=\"T_53825_row6_col1\" class=\"data row6 col1\" >Fast run-off parameter</td>\n",
       "      <td id=\"T_53825_row6_col2\" class=\"data row6 col2\" >0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53825_level0_row7\" class=\"row_heading level0 row7\" ></th>\n",
       "      <td id=\"T_53825_row7_col0\" class=\"data row7 col0\" >Ks</td>\n",
       "      <td id=\"T_53825_row7_col1\" class=\"data row7 col1\" >Slow run-off parameter</td>\n",
       "      <td id=\"T_53825_row7_col2\" class=\"data row7 col2\" >0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53825_level0_row8\" class=\"row_heading level0 row8\" ></th>\n",
       "      <td id=\"T_53825_row8_col0\" class=\"data row8 col0\" >FM</td>\n",
       "      <td id=\"T_53825_row8_col1\" class=\"data row8 col1\" >Degree-day factor</td>\n",
       "      <td id=\"T_53825_row8_col2\" class=\"data row8 col2\" >7.174200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb171389940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print best score\n",
    "print(f\"Best objective score: {best_score:.4f}\")\n",
    "\n",
    "# Round best parameters\n",
    "best_params_list = [round(val, 4) for val in best_params]\n",
    "\n",
    "# Define parameter descriptions (must match param_names)\n",
    "param_descriptions = [\n",
    "    \"Maximum intensity\",\n",
    "    \"Coefficient of evaporation\",\n",
    "    \"Field capacity\",\n",
    "    \"Shape coefficient\",\n",
    "    \"Maximum percolation rate\",\n",
    "    \"Time lag\",\n",
    "    \"Fast run-off parameter\",\n",
    "    \"Slow run-off parameter\",\n",
    "    \"Degree-day factor\"\n",
    "]\n",
    "\n",
    "# Build DataFrame\n",
    "df_params = pd.DataFrame({\n",
    "    \"Parameter\": param_names,\n",
    "    \"Description\": param_descriptions,\n",
    "    \"Value\": best_params_list\n",
    "})\n",
    "\n",
    "# Reset index and drop it for clean display\n",
    "df_params.index = [\"\"] * len(df_params)\n",
    "\n",
    "# Display the styled table\n",
    "display(df_params.style.set_table_styles([\n",
    "    {\"selector\": \"th\", \"props\": [(\"font-weight\", \"bold\")]}\n",
    "]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
